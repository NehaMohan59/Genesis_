{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Prompting\n",
    "\n",
    "Meta prompting is an advanced technique in prompt engineering that emphasizes the structural and syntactical organization of tasks and problems rather than focusing on their specific content. The objective is to create a more abstract, form-driven way of engaging with large language models (LLMs), highlighting patterns and structure over traditional content-focused methods.\n",
    "\n",
    "As outlined by [Zhang et al. (2024)](https://arxiv.org/abs/2311.11482), the defining features of meta prompting include:\n",
    "\n",
    "* Structure-Oriented: Prioritizes the organization and pattern of problems and solutions instead of specific content.\n",
    "* Syntax-Guided: Leverages syntax as a template to shape the expected responses or solutions.\n",
    "* Abstract Frameworks: Uses abstract examples as blueprints, demonstrating the structure of tasks without relying on concrete details.\n",
    "* Domain Versatility: Can be applied across multiple fields, offering structured solutions to diverse problem types.\n",
    "* Categorical Approach: Draws on type theory to organize and categorize components logically, enhancing prompt coherence and precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fmeta.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'What is 984 * log(2)', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "To calculate this, we need to know the value of log(2). The base-10 logarithm of 2 is approximately 0.30103.\n",
      "\n",
      "Now, let's multiply:\n",
      "\n",
      "984 × 0.30103 ≈ 296.41\n",
      "Time taken: 7.575s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## META PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"What is 984 * log(2)\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "\n",
    "# @TODO TO BE COMPLETED\n",
    "PROMPT = MESSAGE \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'You are an AI prompt engineering assistant specializing in educational chatbot development for Discord.\\nYour task is to generate a well-defined prompt that helps perform a requirement analysis for enhancing the functionality of a study companion bot, focusing on simplifying advanced concepts for students.\\n\\nGuidelines for the generated prompt:\\n- Clearly define the objective of the requirement analysis.\\n- Ensure the prompt covers key aspects such as educational features, user engagement, personalized learning approaches, and interaction methods.\\n- Structure the output using bullet points and sections for readability.\\n- The generated prompt should be precise, detailed, and adaptable for AI processing.\\n', 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 300, 'num_predict': 500}}\n",
      "**Prompt: Requirement Analysis for Enhancing Study Companion Bot Functionality**\n",
      "\n",
      "Objective:\n",
      "Analyze and recommend enhancements to a study companion bot to simplify advanced concepts for students, improving their educational experience.\n",
      "\n",
      "**Section 1: Educational Features**\n",
      "\n",
      "* Identify areas where the current study companion bot falls short in explaining complex topics.\n",
      "* Suggest new features that can help bridge this gap, such as:\n",
      "\t+ Interactive simulations or games\n",
      "\t+ Visual explanations (e.g., infographics, videos)\n",
      "\t+ Step-by-step tutorials or problem-solving exercises\n",
      "\t+ Real-world examples or case studies\n",
      "* Consider integrating with existing educational platforms or resources to provide a more comprehensive learning experience.\n",
      "\n",
      "**Section 2: User Engagement**\n",
      "\n",
      "* Analyze the current user engagement metrics and identify areas for improvement.\n",
      "* Suggest features that can increase user interaction, such as:\n",
      "\t+ Personalized learning plans or recommendations\n",
      "\t+ Real-time feedback or progress tracking\n",
      "\t+ Gamification elements (e.g., badges, rewards)\n",
      "\t+ Social sharing or discussion forums\n",
      "* Consider incorporating AI-powered chatbots to provide support and guidance.\n",
      "\n",
      "**Section 3: Accessibility and Inclusivity**\n",
      "\n",
      "* Evaluate the current accessibility features of the study companion bot.\n",
      "* Suggest enhancements that can improve inclusivity for students with disabilities, such as:\n",
      "\t+ Text-to-speech functionality\n",
      "\t+ High contrast mode or font size adjustment\n",
      "\t+ Closed captions or audio descriptions for multimedia content\n",
      "\t+ Accommodations for students with learning difficulties (e.g., slow pace, extra time)\n",
      "\n",
      "**Section 4: Integration and Compatibility**\n",
      "\n",
      "* Assess the current compatibility of the study companion bot with various devices and platforms.\n",
      "* Suggest features that can improve integration with existing systems, such as:\n",
      "\t+ Single sign-on or authentication\n",
      "\t+ Seamless syncing between devices\n",
      "\t+ Compatibility with popular learning management systems (LMS)\n",
      "\t+ Integration with virtual reality (VR) or augmented reality (AR) tools\n",
      "\n",
      "By addressing these areas of improvement, the study companion bot can provide a more comprehensive and effective learning experience for students.\n",
      "Time taken: 34.202s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## META PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = (\n",
    "    \"You are an AI prompt engineering assistant specializing in educational chatbot development for Discord.\\n\"\n",
    "    \"Your task is to generate a well-defined prompt that helps perform a requirement analysis for \"\n",
    "    \"enhancing the functionality of a study companion bot, focusing on simplifying advanced concepts for students.\\n\\n\"\n",
    "\n",
    "    \"Guidelines for the generated prompt:\\n\"\n",
    "    \"- Clearly define the objective of the requirement analysis.\\n\"\n",
    "    \"- Ensure the prompt covers key aspects such as educational features, user engagement, \"\n",
    "    \"personalized learning approaches, and interaction methods.\\n\"\n",
    "    \"- Structure the output using bullet points and sections for readability.\\n\"\n",
    "    \"- The generated prompt should be precise, detailed, and adaptable for AI processing.\\n\"\n",
    ")\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "\n",
    "# @TODO TO BE COMPLETED\n",
    "PROMPT = MESSAGE \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7, \n",
    "                         num_ctx=300, \n",
    "                         num_predict=500)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'You are an AI prompt engineering expert specializing in educational technologies for Discord chatbots.\\n\\nYour task is to generate a meta-prompt that, when executed, produces another prompt that helps perform a structured requirement analysis for enhancing the functionality of a study companion bot, which simplifies advanced concepts for students.\\n\\nThe generated meta-prompt should:\\n- Instruct AI to create a well-defined prompt for requirement analysis.\\n- Ensure the second-level prompt includes structure, clarity, and focus on educational features.\\n- Follow a self-improving approach where AI refines its output before finalizing it.\\n- Use clear bullet points and sections for readability.\\n', 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 400, 'num_predict': 600}}\n",
      "Meta-Prompt:\n",
      "\n",
      "\"Create a structured requirement analysis prompt for enhancing the functionality of a study companion bot that simplifies advanced concepts for students. The generated prompt should be well-defined, clear, and focused on educational features.\n",
      "\n",
      "To achieve this, incorporate the following guidelines into the second-level prompt:\n",
      "\n",
      "• Use concise language and avoid jargon or technical terms that may confuse non-experts.\n",
      "• Ensure the prompt is easy to understand and follow for both educators and bot developers.\n",
      "• Organize the prompt around key areas of interest, such as:\n",
      "\t+ User interface and user experience\n",
      "\t+ Educational content and resources\n",
      "\t+ Personalized learning pathways and recommendations\n",
      "\t+ Integration with existing educational tools and platforms\n",
      "\t+ Accessibility and inclusivity features\n",
      "\n",
      "To improve the prompt's effectiveness, incorporate self-improvement mechanisms that allow AI to refine its output based on feedback from bot developers, educators, and students.\n",
      "\n",
      "• Use a loop of refinement iterations, where AI revises and reiterates the prompt until it meets specific quality standards.\n",
      "• Implement a feedback loop that allows users to provide input on the clarity, relevance, and effectiveness of the generated prompt.\n",
      "• Incorporate natural language processing (NLP) techniques to analyze user feedback and adapt the prompt accordingly.\n",
      "\n",
      "By incorporating these features, AI can generate high-quality prompts that are tailored to the needs of bot developers, educators, and students.\"\n",
      "\n",
      "This revised prompt should provide a solid foundation for generating effective and engaging content for your bot development project.\n",
      "Time taken: 28.13s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## META PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = (\n",
    "    \"You are an AI prompt engineering expert specializing in educational technologies for Discord chatbots.\\n\\n\"\n",
    "\n",
    "    \"Your task is to generate a meta-prompt that, when executed, produces another prompt \"\n",
    "    \"that helps perform a structured requirement analysis for enhancing the functionality of a study companion bot, \"\n",
    "    \"which simplifies advanced concepts for students.\\n\\n\"\n",
    "\n",
    "    \"The generated meta-prompt should:\\n\"\n",
    "    \"- Instruct AI to create a well-defined prompt for requirement analysis.\\n\"\n",
    "    \"- Ensure the second-level prompt includes structure, clarity, and focus on educational features.\\n\"\n",
    "    \"- Follow a self-improving approach where AI refines its output before finalizing it.\\n\"\n",
    "    \"- Use clear bullet points and sections for readability.\\n\"\n",
    ")\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "\n",
    "# @TODO TO BE COMPLETED\n",
    "PROMPT = MESSAGE \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7, \n",
    "                         num_ctx=400, \n",
    "                         num_predict=600)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
